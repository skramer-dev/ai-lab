{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchmetrics\n",
    "\n",
    "import time\n",
    "import torch.cuda\n",
    "from flash.image import ImageClassificationData, ImageClassifier\n",
    "import flash\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from timm.loss import LabelSmoothingCrossEntropy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio as iio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [],
   "source": [
    "DATA_PATH = '../../Pokemon-data/'\n",
    "SEED = 42\n",
    "\n",
    "# define training hyperparameters\n",
    "INIT_LR = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "# define the train and val splits\n",
    "TRAIN_SPLIT = 0.75\n",
    "VAL_SPLIT = 1 - TRAIN_SPLIT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('metadata/pokemon.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['abilities', 'against_bug', 'against_dark', 'against_dragon',\n",
      "       'against_electric', 'against_fairy', 'against_fight', 'against_fire',\n",
      "       'against_flying', 'against_ghost', 'against_grass', 'against_ground',\n",
      "       'against_ice', 'against_normal', 'against_poison', 'against_psychic',\n",
      "       'against_rock', 'against_steel', 'against_water', 'attack',\n",
      "       'base_egg_steps', 'base_happiness', 'base_total', 'capture_rate',\n",
      "       'classfication', 'defense', 'experience_growth', 'height_m', 'hp',\n",
      "       'japanese_name', 'name', 'percentage_male', 'pokedex_number',\n",
      "       'sp_attack', 'sp_defense', 'speed', 'type1', 'type2', 'weight_kg',\n",
      "       'generation', 'is_legendary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(metadata.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [],
   "source": [
    "pokemon_names = [x for x in os.listdir(DATA_PATH)]\n",
    "\n",
    "# remove the IDE metafile that was included in the os.listdir\n",
    "#pokemon_names = pokemon_names[1:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [],
   "source": [
    "# get slice from metadata file based on the pokemon used in training\n",
    "filtered_metadata = metadata[metadata.name.isin(pokemon_names)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [],
   "source": [
    "# convert dataframe to list for easier comparison\n",
    "filtered_list = filtered_metadata.loc[:,'name'].tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# check for differences in training data and the metadata file\n",
    "print([x for x in pokemon_names if x not in filtered_list])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [],
   "source": [
    "filtered_metadata = filtered_metadata.loc[:,['name', 'type1']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of            name    type1\n",
      "0     Bulbasaur    grass\n",
      "1       Ivysaur    grass\n",
      "2      Venusaur    grass\n",
      "3    Charmander     fire\n",
      "4    Charmeleon     fire\n",
      "..          ...      ...\n",
      "146     Dratini   dragon\n",
      "147   Dragonair   dragon\n",
      "148   Dragonite   dragon\n",
      "149      Mewtwo  psychic\n",
      "150         Mew  psychic\n",
      "\n",
      "[149 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(filtered_metadata.head)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [],
   "source": [
    "def compile_training_data_to_list():\n",
    "    all_data = []\n",
    "    for pokemon in os.listdir(DATA_PATH):\n",
    "        all_data += [pokemon + '/' + x for x in os.listdir(DATA_PATH + pokemon)]\n",
    "\n",
    "    results = create_annotated_dataframe(all_data)\n",
    "    return results\n",
    "\n",
    "def create_annotated_dataframe(all_data):\n",
    "    base_data = {'file_name': [], 'name': [], 'label': []}\n",
    "    for item in all_data:\n",
    "        base_data['file_name'].append(item)\n",
    "        base_data['name'].append(item.split('/')[0])\n",
    "        # yes, this is a bit ugly, but we have to match with the metadata\n",
    "        base_data['label'].append(\n",
    "            filtered_metadata[\n",
    "                filtered_metadata['name']==(item.split('/')[0])\n",
    "            ].loc[:,'type1'].tolist()[0])\n",
    "\n",
    "    results = create_encoded_dataframe(base_data)\n",
    "    return results\n",
    "\n",
    "def create_encoded_dataframe(base_data):\n",
    "    results = pd.DataFrame(base_data, columns = ['file_name', 'name', 'label'])\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(results['label'])\n",
    "    results['label'] = np.int64(labels)\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [],
   "source": [
    "encoded_data = compile_training_data_to_list()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       file_name   name  label\n",
      "0      Abra/0282b2f3a22745f1a436054ea15a0ae5.jpg   Abra     12\n",
      "1      Abra/06b9eec4827d4d49b1b4c284308708df.jpg   Abra     12\n",
      "2      Abra/10a9f06ec6524c66b779ea80354f8519.jpg   Abra     12\n",
      "3      Abra/1788abb8b51f48509cfac8067bd99e14.jpg   Abra     12\n",
      "4      Abra/28cfad92ad934d1f9b579cbff4b5d012.jpg   Abra     12\n",
      "...                                          ...    ...    ...\n",
      "6791  Zubat/dd387067380e4d1f8672c30d4b567fac.jpg  Zubat     11\n",
      "6792  Zubat/e1997a18e61641a4b0e701f6bc4c70f4.jpg  Zubat     11\n",
      "6793  Zubat/e6cba9a117d64d849fcc389e04e92e11.jpg  Zubat     11\n",
      "6794  Zubat/f8788465c10a4ab8bb0aeb992ec060ce.jpg  Zubat     11\n",
      "6795  Zubat/fccfe4de71a543349378b09d91d3f745.jpg  Zubat     11\n",
      "\n",
      "[6796 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\tdef __init__(self, x, y, img_dir):\n",
    "\t\tself.x = x\n",
    "\t\tself.y = y\n",
    "\t\tself.img_dir = img_dir\n",
    "\t\tself.classes = np.unique(self.y)\n",
    "\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.x)\n",
    "\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timg_path = os.path.join(self.img_dir, self.x[idx])\n",
    "        # use the slice to remove a possible 4th alpha channel\n",
    "\t\timage = iio.v2.imread(img_path)[:,:,:3]\n",
    "\t\tlabel = self.y[idx]\n",
    "\t\treturn image, label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [],
   "source": [
    "def stratified_split(dataset):\n",
    "    x_train, x_val, y_train, y_val = train_test_split(dataset['file_name'].to_numpy(),\n",
    "                                                  dataset['label'].to_numpy(),\n",
    "                                                  test_size=0.25,\n",
    "                                                  stratify=dataset['label'],\n",
    "                                                  random_state=SEED)\n",
    "\n",
    "    train = CustomDataset(x_train, y_train, DATA_PATH)\n",
    "    val = CustomDataset(x_val, y_val, DATA_PATH)\n",
    "    return train, val"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [],
   "source": [
    "dataset = compile_training_data_to_list()\n",
    "train, val = stratified_split(dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [],
   "source": [
    "datamodule = ImageClassificationData.from_datasets(train_dataset=train,\n",
    "                                                   val_dataset=val,\n",
    "                                                   batch_size=BATCH_SIZE,\n",
    "                                                   )\n",
    "performance_metrics = [torchmetrics.Accuracy(),\n",
    "                      torchmetrics.F1Score(num_classes=len(train.classes), average='macro')]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 'efficientnet_b0' provided by rwightman/pytorch-image-models (https://github.com/rwightman/pytorch-image-models).\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "model = ImageClassifier(backbone='efficientnet_b0',\n",
    "                        labels=train.classes,\n",
    "                        metrics=performance_metrics,\n",
    "                        loss_fn=LabelSmoothingCrossEntropy(0.02),\n",
    "                        optimizer=\"AdamW\",\n",
    "                        learning_rate=INIT_LR, )\n",
    "\n",
    "logger = CSVLogger(save_dir='logs/')\n",
    "\n",
    "trainer = flash.Trainer(max_epochs=EPOCHS,\n",
    "                        gpus=torch.cuda.device_count(),\n",
    "                        logger=logger)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CYBORGX\\anaconda3\\envs\\birdclef\\lib\\site-packages\\flash\\core\\trainer.py:213: UserWarning: The model contains a default finetune callback.\n",
      "  warnings.warn(\"The model contains a default finetune callback.\", UserWarning)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type           | Params\n",
      "-------------------------------------------------\n",
      "0 | loss_fn       | ModuleDict     | 0     \n",
      "1 | train_metrics | ModuleDict     | 0     \n",
      "2 | val_metrics   | ModuleDict     | 0     \n",
      "3 | test_metrics  | ModuleDict     | 0     \n",
      "4 | adapter       | DefaultAdapter | 4.0 M \n",
      "-------------------------------------------------\n",
      "4.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 M     Total params\n",
      "16.107    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e4b4478157e34dbc9d009a47f54df242"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CYBORGX\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\CYBORGX\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d33c9e2ef80347308c89dd3af68e51e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Could not find a backend to open `../../Pokemon-data/Cloyster/ff270ebfab0f46b3b05c3fecd6a15ef9.svg`` with iomode `ri`.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [229]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m startTime \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfinetune\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mno_freeze\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m endTime \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[INFO] total time taken to train the model: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m(endTime \u001B[38;5;241m-\u001B[39m startTime) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m60\u001B[39m \u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124mmin\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\flash\\core\\trainer.py:164\u001B[0m, in \u001B[0;36mTrainer.finetune\u001B[1;34m(self, model, train_dataloader, val_dataloaders, datamodule, strategy, train_bn)\u001B[0m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    132\u001B[0m \n\u001B[0;32m    133\u001B[0m \u001B[38;5;124;03mRuns the full optimization routine. Same as :meth:`pytorch_lightning.Trainer.fit`, but unfreezes layers\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;124;03m    train_bn: Whether to train Batch Norm layer\u001B[39;00m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    163\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_resolve_callbacks(model, strategy, train_bn\u001B[38;5;241m=\u001B[39mtrain_bn)\n\u001B[1;32m--> 164\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:740\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001B[0m\n\u001B[0;32m    735\u001B[0m     rank_zero_deprecation(\n\u001B[0;32m    736\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    737\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Use `trainer.fit(train_dataloaders)` instead. HINT: added \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    738\u001B[0m     )\n\u001B[0;32m    739\u001B[0m     train_dataloaders \u001B[38;5;241m=\u001B[39m train_dataloader\n\u001B[1;32m--> 740\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    741\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[0;32m    742\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:685\u001B[0m, in \u001B[0;36mTrainer._call_and_handle_interrupt\u001B[1;34m(self, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[0;32m    675\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    676\u001B[0m \u001B[38;5;124;03mError handling, intended to be used only for main trainer function entry points (fit, validate, test, predict)\u001B[39;00m\n\u001B[0;32m    677\u001B[0m \u001B[38;5;124;03mas all errors should funnel through them\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    682\u001B[0m \u001B[38;5;124;03m    **kwargs: keyword arguments to be passed to `trainer_fn`\u001B[39;00m\n\u001B[0;32m    683\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    684\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 685\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m trainer_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    686\u001B[0m \u001B[38;5;66;03m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001B[39;00m\n\u001B[0;32m    687\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exception:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:777\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[0;32m    775\u001B[0m \u001B[38;5;66;03m# TODO: ckpt_path only in v1.7\u001B[39;00m\n\u001B[0;32m    776\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m ckpt_path \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresume_from_checkpoint\n\u001B[1;32m--> 777\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    779\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[0;32m    780\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1199\u001B[0m, in \u001B[0;36mTrainer._run\u001B[1;34m(self, model, ckpt_path)\u001B[0m\n\u001B[0;32m   1196\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheckpoint_connector\u001B[38;5;241m.\u001B[39mresume_end()\n\u001B[0;32m   1198\u001B[0m \u001B[38;5;66;03m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001B[39;00m\n\u001B[1;32m-> 1199\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1201\u001B[0m \u001B[38;5;66;03m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001B[39;00m\n\u001B[0;32m   1202\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post_dispatch()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1279\u001B[0m, in \u001B[0;36mTrainer._dispatch\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1277\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_type_plugin\u001B[38;5;241m.\u001B[39mstart_predicting(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m   1278\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1279\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_type_plugin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_training\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\plugins\\training_type\\training_type_plugin.py:202\u001B[0m, in \u001B[0;36mTrainingTypePlugin.start_training\u001B[1;34m(self, trainer)\u001B[0m\n\u001B[0;32m    200\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstart_training\u001B[39m(\u001B[38;5;28mself\u001B[39m, trainer: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpl.Trainer\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;66;03m# double dispatch to initiate the training loop\u001B[39;00m\n\u001B[1;32m--> 202\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_results \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1289\u001B[0m, in \u001B[0;36mTrainer.run_stage\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1287\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredicting:\n\u001B[0;32m   1288\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_predict()\n\u001B[1;32m-> 1289\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1319\u001B[0m, in \u001B[0;36mTrainer._run_train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1317\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_loop\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\n\u001B[0;32m   1318\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n\u001B[1;32m-> 1319\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\loops\\base.py:145\u001B[0m, in \u001B[0;36mLoop.run\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    144\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 145\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madvance(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    146\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[0;32m    147\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrestarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:234\u001B[0m, in \u001B[0;36mFitLoop.advance\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    231\u001B[0m data_fetcher \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39m_data_connector\u001B[38;5;241m.\u001B[39mget_profiled_dataloader(dataloader)\n\u001B[0;32m    233\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_training_epoch\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 234\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepoch_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_fetcher\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    236\u001B[0m     \u001B[38;5;66;03m# the global step is manually decreased here due to backwards compatibility with existing loggers\u001B[39;00m\n\u001B[0;32m    237\u001B[0m     \u001B[38;5;66;03m# as they expect that the same step is used when logging epoch end metrics even when the batch loop has\u001B[39;00m\n\u001B[0;32m    238\u001B[0m     \u001B[38;5;66;03m# finished. this means the attribute does not exactly track the number of optimizer steps applied.\u001B[39;00m\n\u001B[0;32m    239\u001B[0m     \u001B[38;5;66;03m# TODO(@carmocca): deprecate and rename so users don't get confused\u001B[39;00m\n\u001B[0;32m    240\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\loops\\base.py:145\u001B[0m, in \u001B[0;36mLoop.run\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    144\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 145\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madvance(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    146\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[0;32m    147\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrestarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\training_epoch_loop.py:156\u001B[0m, in \u001B[0;36mTrainingEpochLoop.advance\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    152\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrestarting \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_check_val_fx(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_idx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_progress\u001B[38;5;241m.\u001B[39mis_last_batch):\n\u001B[0;32m    153\u001B[0m     \u001B[38;5;66;03m# skip training and run validation in `on_advance_end`\u001B[39;00m\n\u001B[0;32m    154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m--> 156\u001B[0m batch_idx, (batch, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_progress\u001B[38;5;241m.\u001B[39mis_last_batch) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataloader_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39m_data_connector\u001B[38;5;241m.\u001B[39mtrain_data_fetcher\u001B[38;5;241m.\u001B[39mstore_on_device:\n\u001B[0;32m    159\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining_batch_to_device\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\utilities\\fetching.py:203\u001B[0m, in \u001B[0;36mAbstractDataFetcher.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 203\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetching_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\utilities\\fetching.py:270\u001B[0m, in \u001B[0;36mDataFetcher.fetching_function\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    268\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    269\u001B[0m     yield_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpop_batch()\n\u001B[1;32m--> 270\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fetch_next_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    272\u001B[0m     \u001B[38;5;66;03m# wait for batch to be available.\u001B[39;00m\n\u001B[0;32m    273\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwait()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\utilities\\fetching.py:300\u001B[0m, in \u001B[0;36mDataFetcher._fetch_next_batch\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    298\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_fetch_start()\n\u001B[0;32m    299\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_profiler(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfetch_next_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstage\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_batch\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 300\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    301\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfetched \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    302\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_fetch_end(batch, data)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\trainer\\supporters.py:550\u001B[0m, in \u001B[0;36mCombinedLoaderIterator.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    544\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    545\u001B[0m     \u001B[38;5;124;03m\"\"\"Fetches the next batch from multiple data loaders.\u001B[39;00m\n\u001B[0;32m    546\u001B[0m \n\u001B[0;32m    547\u001B[0m \u001B[38;5;124;03m    Returns:\u001B[39;00m\n\u001B[0;32m    548\u001B[0m \u001B[38;5;124;03m        a collections of batch data\u001B[39;00m\n\u001B[0;32m    549\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 550\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest_next_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloader_iters\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\trainer\\supporters.py:562\u001B[0m, in \u001B[0;36mCombinedLoaderIterator.request_next_batch\u001B[1;34m(loader_iters)\u001B[0m\n\u001B[0;32m    552\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    553\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest_next_batch\u001B[39m(loader_iters: Union[Iterator, Sequence, Mapping]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    554\u001B[0m     \u001B[38;5;124;03m\"\"\"Return the batch of data from multiple iterators.\u001B[39;00m\n\u001B[0;32m    555\u001B[0m \n\u001B[0;32m    556\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    560\u001B[0m \u001B[38;5;124;03m        Any: a collections of batch data\u001B[39;00m\n\u001B[0;32m    561\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mapply_to_collection\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloader_iters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\utilities\\apply_func.py:96\u001B[0m, in \u001B[0;36mapply_to_collection\u001B[1;34m(data, dtype, function, wrong_dtype, include_none, *args, **kwargs)\u001B[0m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;66;03m# Breaking condition\u001B[39;00m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, dtype) \u001B[38;5;129;01mand\u001B[39;00m (wrong_dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, wrong_dtype)):\n\u001B[1;32m---> 96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m function(data, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     98\u001B[0m elem_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(data)\n\u001B[0;32m    100\u001B[0m \u001B[38;5;66;03m# Recursively apply to collection items\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    528\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    529\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()\n\u001B[1;32m--> 530\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    531\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    532\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    533\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    534\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    569\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 570\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    571\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    572\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\flash\\core\\data\\io\\input.py:323\u001B[0m, in \u001B[0;36mInput.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    322\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index: \u001B[38;5;28mint\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m--> 323\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_load_sample(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m]\u001B[49m)\n",
      "Input \u001B[1;32mIn [224]\u001B[0m, in \u001B[0;36mCustomDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     14\u001B[0m \t\timg_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimg_dir, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx[idx])\n\u001B[0;32m     15\u001B[0m         \u001B[38;5;66;03m# use the slice to remove a possible 4th alpha channel\u001B[39;00m\n\u001B[1;32m---> 16\u001B[0m \t\timage \u001B[38;5;241m=\u001B[39m \u001B[43miio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_path\u001B[49m\u001B[43m)\u001B[49m[:,:,:\u001B[38;5;241m3\u001B[39m]\n\u001B[0;32m     17\u001B[0m \t\tlabel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my[idx]\n\u001B[0;32m     18\u001B[0m \t\t\u001B[38;5;28;01mreturn\u001B[39;00m image, label\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\imageio\\v2.py:200\u001B[0m, in \u001B[0;36mimread\u001B[1;34m(uri, format, **kwargs)\u001B[0m\n\u001B[0;32m    197\u001B[0m imopen_args \u001B[38;5;241m=\u001B[39m decypher_format_arg(\u001B[38;5;28mformat\u001B[39m)\n\u001B[0;32m    198\u001B[0m imopen_args[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlegacy_mode\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 200\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m imopen(uri, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mri\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mimopen_args) \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m file\u001B[38;5;241m.\u001B[39mread(index\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\imageio\\core\\imopen.py:303\u001B[0m, in \u001B[0;36mimopen\u001B[1;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001B[0m\n\u001B[0;32m    297\u001B[0m         err_msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    298\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mBased on the extension, the following plugins might add capable backends:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    299\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00minstall_candidates\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    300\u001B[0m         )\n\u001B[0;32m    302\u001B[0m request\u001B[38;5;241m.\u001B[39mfinish()\n\u001B[1;32m--> 303\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m err_type(err_msg)\n",
      "\u001B[1;31mValueError\u001B[0m: Could not find a backend to open `../../Pokemon-data/Cloyster/ff270ebfab0f46b3b05c3fecd6a15ef9.svg`` with iomode `ri`."
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "trainer.finetune(model,\n",
    "                 datamodule=datamodule,\n",
    "                 strategy='no_freeze')\n",
    "\n",
    "endTime = time.time()\n",
    "print(f\"[INFO] total time taken to train the model: {(endTime - startTime) / 60 :.2f}min\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"saved-models/B0-Un.pt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics = pd.read_csv(f'{trainer.logger.log_dir}/metrics.csv')\n",
    "display(metrics)\n",
    "del metrics[\"epoch\"]\n",
    "metrics.set_index(\"step\", inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "sns.relplot(data=metrics, kind=\"line\", height=20)\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
