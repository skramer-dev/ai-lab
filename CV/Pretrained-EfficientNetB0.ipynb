{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pytorch_lightning.utilities.seed\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchmetrics\n",
    "\n",
    "import time\n",
    "import torch.cuda\n",
    "from flash.image import ImageClassificationData, ImageClassifier\n",
    "import flash\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from flash import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [],
   "source": [
    "DATA_PATH = '../../Pokemon-data/'\n",
    "NORMALIZED_DATA = '../../Training-baseline/'\n",
    "SEED = 42\n",
    "\n",
    "# define training hyperparameters\n",
    "INIT_LR = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 3\n",
    "FINETUNE_STRATEGY = 'no_freeze'\n",
    "VERSION = (str(EPOCHS) + 'Epoch-' + FINETUNE_STRATEGY)\n",
    "# define the train and val splits\n",
    "TRAIN_SPLIT = 0.75\n",
    "VAL_SPLIT = 1 - TRAIN_SPLIT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": "42"
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_lightning.utilities.seed.seed_everything(SEED)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('metadata/pokemon.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['abilities', 'against_bug', 'against_dark', 'against_dragon',\n",
      "       'against_electric', 'against_fairy', 'against_fight', 'against_fire',\n",
      "       'against_flying', 'against_ghost', 'against_grass', 'against_ground',\n",
      "       'against_ice', 'against_normal', 'against_poison', 'against_psychic',\n",
      "       'against_rock', 'against_steel', 'against_water', 'attack',\n",
      "       'base_egg_steps', 'base_happiness', 'base_total', 'capture_rate',\n",
      "       'classfication', 'defense', 'experience_growth', 'height_m', 'hp',\n",
      "       'japanese_name', 'name', 'percentage_male', 'pokedex_number',\n",
      "       'sp_attack', 'sp_defense', 'speed', 'type1', 'type2', 'weight_kg',\n",
      "       'generation', 'is_legendary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(metadata.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [],
   "source": [
    "pokemon_names = [x for x in os.listdir(NORMALIZED_DATA)]\n",
    "\n",
    "# remove the IDE metafile that was included in the os.listdir\n",
    "#pokemon_names = pokemon_names[1:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [],
   "source": [
    "# get slice from metadata file based on the pokemon used in training\n",
    "filtered_metadata = metadata[metadata.name.isin(pokemon_names)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [],
   "source": [
    "# convert dataframe to list for easier comparison\n",
    "filtered_list = filtered_metadata.loc[:,'name'].tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# check for differences in training data and the metadata file\n",
    "print([x for x in pokemon_names if x not in filtered_list])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [
    "filtered_metadata = filtered_metadata.loc[:,['name', 'type1']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of            name   type1\n",
      "0     Bulbasaur   grass\n",
      "1       Ivysaur   grass\n",
      "2      Venusaur   grass\n",
      "3    Charmander    fire\n",
      "4    Charmeleon    fire\n",
      "..          ...     ...\n",
      "714     Noivern  flying\n",
      "715     Xerneas   fairy\n",
      "716     Yveltal    dark\n",
      "718     Diancie    rock\n",
      "720   Volcanion    fire\n",
      "\n",
      "[703 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(filtered_metadata.head)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [],
   "source": [
    "def compile_training_data_to_list():\n",
    "    all_data = []\n",
    "    for pokemon in os.listdir(NORMALIZED_DATA):\n",
    "        all_data += [pokemon + '/' + x for x in os.listdir(NORMALIZED_DATA + pokemon)]\n",
    "\n",
    "    results = create_annotated_dataframe(all_data)\n",
    "    return results\n",
    "\n",
    "def create_annotated_dataframe(all_data):\n",
    "    base_data = {'file_name': [], 'name': [], 'label': []}\n",
    "    for item in all_data:\n",
    "        base_data['file_name'].append(item)\n",
    "        base_data['name'].append(item.split('/')[0])\n",
    "        # yes, this is a bit ugly, but we have to match with the metadata\n",
    "        base_data['label'].append(\n",
    "            filtered_metadata[\n",
    "                filtered_metadata['name']==(item.split('/')[0])\n",
    "            ].loc[:,'type1'].tolist()[0])\n",
    "\n",
    "    results = create_encoded_dataframe(base_data)\n",
    "    return results\n",
    "\n",
    "def create_encoded_dataframe(base_data):\n",
    "    results = pd.DataFrame(base_data, columns = ['file_name', 'name', 'label'])\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(results['label'])\n",
    "    results['label'] = np.int64(labels)\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [],
   "source": [
    "encoded_data = compile_training_data_to_list()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            file_name       name  label\n",
      "0      Abomasnow/dcedzyqfojskcahp.npy  Abomasnow      9\n",
      "1      Abomasnow/gqfpsmqasdqiknur.npy  Abomasnow      9\n",
      "2      Abomasnow/imzcvkkckbdchpro.npy  Abomasnow      9\n",
      "3      Abomasnow/kzibfmivzksykiwy.npy  Abomasnow      9\n",
      "4      Abomasnow/mjtasvyoonxyilqt.npy  Abomasnow      9\n",
      "...                               ...        ...    ...\n",
      "12074   Zweilous/nrpzbrzmxehydoqj.npy   Zweilous      1\n",
      "12075   Zweilous/qjoppeepmpyujyao.npy   Zweilous      1\n",
      "12076   Zweilous/sihxufnlbmephyeq.npy   Zweilous      1\n",
      "12077   Zweilous/vshewhewmkutsdlp.npy   Zweilous      1\n",
      "12078   Zweilous/ytpdigaymlnyrpbd.npy   Zweilous      1\n",
      "\n",
      "[12079 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y, img_dir):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.img_dir = img_dir\n",
    "        self.classes = np.unique(self.y)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.x[idx])\n",
    "        # use the slice to remove a possible 4th alpha channel\n",
    "        image = np.load(img_path)[:, :, :3]\n",
    "        image = image.astype(np.float32)\n",
    "        label = self.y[idx]\n",
    "        return image, label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [],
   "source": [
    "def stratified_split(dataset):\n",
    "    x_train, x_val, y_train, y_val = train_test_split(dataset['file_name'].to_numpy(),\n",
    "                                                  dataset['label'].to_numpy(),\n",
    "                                                  test_size=0.25,\n",
    "                                                  stratify=dataset['label'],\n",
    "                                                  random_state=SEED)\n",
    "\n",
    "    train = CustomDataset(x_train, y_train, NORMALIZED_DATA)\n",
    "    val = CustomDataset(x_val, y_val, NORMALIZED_DATA)\n",
    "    return train, val"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [],
   "source": [
    "dataset = compile_training_data_to_list()\n",
    "train, val = stratified_split(dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "outputs": [],
   "source": [
    "datamodule = ImageClassificationData.from_datasets(train_dataset=train,\n",
    "                                                   val_dataset=val,\n",
    "                                                   batch_size=BATCH_SIZE,\n",
    "                                                   )\n",
    "performance_metrics = [torchmetrics.Accuracy(),\n",
    "                      torchmetrics.F1Score(num_classes=len(train.classes), average='macro')]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 'efficientnet_b0' provided by rwightman/pytorch-image-models (https://github.com/rwightman/pytorch-image-models).\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "model = ImageClassifier(backbone='efficientnet_b0',\n",
    "                        pretrained=False,\n",
    "                        labels=train.classes,\n",
    "                        metrics=performance_metrics,\n",
    "                        optimizer=\"AdamW\",\n",
    "                        learning_rate=INIT_LR, )\n",
    "\n",
    "logger = CSVLogger(save_dir='logs/', version=VERSION, name='not-pretrained')\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_f1score\", patience=3, verbose=False, mode=\"max\")\n",
    "\n",
    "trainer = flash.Trainer(max_epochs=EPOCHS,\n",
    "                        gpus=torch.cuda.device_count(),\n",
    "                        logger=logger,\n",
    "                        callbacks=[early_stop_callback])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CYBORGX\\anaconda3\\envs\\birdclef\\lib\\site-packages\\flash\\core\\trainer.py:213: UserWarning: The model contains a default finetune callback.\n",
      "  warnings.warn(\"The model contains a default finetune callback.\", UserWarning)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\CYBORGX\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\loggers\\csv_logs.py:57: UserWarning: Experiment logs directory logs/not-pretrained\\3Epoch-no_freeze exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name          | Type           | Params\n",
      "-------------------------------------------------\n",
      "0 | train_metrics | ModuleDict     | 0     \n",
      "1 | val_metrics   | ModuleDict     | 0     \n",
      "2 | test_metrics  | ModuleDict     | 0     \n",
      "3 | adapter       | DefaultAdapter | 4.0 M \n",
      "-------------------------------------------------\n",
      "4.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 M     Total params\n",
      "16.122    Total estimated model params size (MB)\n",
      "C:\\Users\\CYBORGX\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:631: UserWarning: Checkpoint directory logs/not-pretrained\\3Epoch-no_freeze\\checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1edb8c5cdc1b4f58a57cfa0b024e2b79"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "trainer.finetune(model,\n",
    "                 datamodule=datamodule,\n",
    "                 strategy=FINETUNE_STRATEGY)\n",
    "\n",
    "endTime = time.time()\n",
    "print(f\"[INFO] total time taken to train the model: {(endTime - startTime) / 60 :.2f}min\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"saved-models/\" + VERSION + \".pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics = pd.read_csv(f'{trainer.logger.log_dir}/metrics.csv')\n",
    "display(metrics)\n",
    "del metrics[\"epoch\"]\n",
    "metrics.set_index(\"step\", inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(filtered_metadata['type1'])\n",
    "filtered_metadata['encoded_label'] = labels\n",
    "\n",
    "type_list = filtered_metadata['type1'].unique()\n",
    "enc_type_list = filtered_metadata['encoded_label'].unique()\n",
    "\n",
    "type_lookup = pd.DataFrame(list(zip(type_list, enc_type_list)), columns=['Type_name', 'encoded_type'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "pred_data = ImageClassificationData.from_files(\n",
    "    predict_files=[\n",
    "        '../../Training-baseline/Growlithe/2d7043870a8843f08b3267d9c70885c3.npy',\n",
    "        '../../Training-baseline/Cloyster/6cb25d6053c4480e98c5b3073d811ec5.npy'\n",
    "    ],\n",
    "    batch_size = 1\n",
    ")\n",
    "\n",
    "\n",
    "predictions = trainer.predict(model, datamodule=pred_data, output='labels')\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "print(f\"\"\"\n",
    "- Pokemon had the predicted type:\n",
    "{type_lookup.loc[type_lookup['encoded_type'] == predictions[0][0]]}\n",
    "---------------------------------------------------------------------\n",
    "- The Pokemon in Question actually has the type:\n",
    "{filtered_metadata[filtered_metadata['name'] == 'Growlithe']}\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
