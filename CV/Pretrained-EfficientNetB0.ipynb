{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchmetrics\n",
    "\n",
    "import time\n",
    "import torch.cuda\n",
    "from flash.image import ImageClassificationData, ImageClassifier\n",
    "import flash\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from timm.loss import LabelSmoothingCrossEntropy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio as iio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "DATA_PATH = '../../Pokemon-data/'\n",
    "NORMALIZED_DATA = '../../Training-baseline/'\n",
    "SEED = 42\n",
    "\n",
    "# define training hyperparameters\n",
    "INIT_LR = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "# define the train and val splits\n",
    "TRAIN_SPLIT = 0.75\n",
    "VAL_SPLIT = 1 - TRAIN_SPLIT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('metadata/pokemon.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['abilities', 'against_bug', 'against_dark', 'against_dragon',\n",
      "       'against_electric', 'against_fairy', 'against_fight', 'against_fire',\n",
      "       'against_flying', 'against_ghost', 'against_grass', 'against_ground',\n",
      "       'against_ice', 'against_normal', 'against_poison', 'against_psychic',\n",
      "       'against_rock', 'against_steel', 'against_water', 'attack',\n",
      "       'base_egg_steps', 'base_happiness', 'base_total', 'capture_rate',\n",
      "       'classfication', 'defense', 'experience_growth', 'height_m', 'hp',\n",
      "       'japanese_name', 'name', 'percentage_male', 'pokedex_number',\n",
      "       'sp_attack', 'sp_defense', 'speed', 'type1', 'type2', 'weight_kg',\n",
      "       'generation', 'is_legendary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(metadata.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "pokemon_names = [x for x in os.listdir(NORMALIZED_DATA)]\n",
    "\n",
    "# remove the IDE metafile that was included in the os.listdir\n",
    "#pokemon_names = pokemon_names[1:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "# get slice from metadata file based on the pokemon used in training\n",
    "filtered_metadata = metadata[metadata.name.isin(pokemon_names)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "# convert dataframe to list for easier comparison\n",
    "filtered_list = filtered_metadata.loc[:,'name'].tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# check for differences in training data and the metadata file\n",
    "print([x for x in pokemon_names if x not in filtered_list])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "filtered_metadata = filtered_metadata.loc[:,['name', 'type1']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of            name   type1\n",
      "0     Bulbasaur   grass\n",
      "1       Ivysaur   grass\n",
      "2      Venusaur   grass\n",
      "3    Charmander    fire\n",
      "4    Charmeleon    fire\n",
      "..          ...     ...\n",
      "714     Noivern  flying\n",
      "715     Xerneas   fairy\n",
      "716     Yveltal    dark\n",
      "718     Diancie    rock\n",
      "720   Volcanion    fire\n",
      "\n",
      "[703 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(filtered_metadata.head)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "def compile_training_data_to_list():\n",
    "    all_data = []\n",
    "    for pokemon in os.listdir(NORMALIZED_DATA):\n",
    "        all_data += [pokemon + '/' + x for x in os.listdir(NORMALIZED_DATA + pokemon)]\n",
    "\n",
    "    results = create_annotated_dataframe(all_data)\n",
    "    return results\n",
    "\n",
    "def create_annotated_dataframe(all_data):\n",
    "    base_data = {'file_name': [], 'name': [], 'label': []}\n",
    "    for item in all_data:\n",
    "        base_data['file_name'].append(item)\n",
    "        base_data['name'].append(item.split('/')[0])\n",
    "        # yes, this is a bit ugly, but we have to match with the metadata\n",
    "        base_data['label'].append(\n",
    "            filtered_metadata[\n",
    "                filtered_metadata['name']==(item.split('/')[0])\n",
    "            ].loc[:,'type1'].tolist()[0])\n",
    "\n",
    "    results = create_encoded_dataframe(base_data)\n",
    "    return results\n",
    "\n",
    "def create_encoded_dataframe(base_data):\n",
    "    results = pd.DataFrame(base_data, columns = ['file_name', 'name', 'label'])\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(results['label'])\n",
    "    results['label'] = np.int64(labels)\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "encoded_data = compile_training_data_to_list()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            file_name       name  label\n",
      "0      Abomasnow/dcedzyqfojskcahp.jpg  Abomasnow      9\n",
      "1      Abomasnow/gqfpsmqasdqiknur.png  Abomasnow      9\n",
      "2      Abomasnow/imzcvkkckbdchpro.png  Abomasnow      9\n",
      "3      Abomasnow/kzibfmivzksykiwy.png  Abomasnow      9\n",
      "4      Abomasnow/mjtasvyoonxyilqt.png  Abomasnow      9\n",
      "...                               ...        ...    ...\n",
      "12091   Zweilous/nrpzbrzmxehydoqj.png   Zweilous      1\n",
      "12092   Zweilous/qjoppeepmpyujyao.png   Zweilous      1\n",
      "12093   Zweilous/sihxufnlbmephyeq.png   Zweilous      1\n",
      "12094   Zweilous/vshewhewmkutsdlp.png   Zweilous      1\n",
      "12095   Zweilous/ytpdigaymlnyrpbd.png   Zweilous      1\n",
      "\n",
      "[12096 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\tdef __init__(self, x, y, img_dir):\n",
    "\t\tself.x = x\n",
    "\t\tself.y = y\n",
    "\t\tself.img_dir = img_dir\n",
    "\t\tself.classes = np.unique(self.y)\n",
    "\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.x)\n",
    "\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timg_path = os.path.join(self.img_dir, self.x[idx])\n",
    "        # use the slice to remove a possible 4th alpha channel\n",
    "\t\timage = iio.v2.imread(img_path)[:,:,:3]\n",
    "\t\tlabel = self.y[idx]\n",
    "\t\treturn image, label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "def stratified_split(dataset):\n",
    "    x_train, x_val, y_train, y_val = train_test_split(dataset['file_name'].to_numpy(),\n",
    "                                                  dataset['label'].to_numpy(),\n",
    "                                                  test_size=0.25,\n",
    "                                                  stratify=dataset['label'],\n",
    "                                                  random_state=SEED)\n",
    "\n",
    "    train = CustomDataset(x_train, y_train, NORMALIZED_DATA)\n",
    "    val = CustomDataset(x_val, y_val, NORMALIZED_DATA)\n",
    "    return train, val"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "dataset = compile_training_data_to_list()\n",
    "train, val = stratified_split(dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "datamodule = ImageClassificationData.from_datasets(train_dataset=train,\n",
    "                                                   val_dataset=val,\n",
    "                                                   batch_size=BATCH_SIZE,\n",
    "                                                   )\n",
    "performance_metrics = [torchmetrics.Accuracy(),\n",
    "                      torchmetrics.F1Score(num_classes=len(train.classes), average='macro')]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 'efficientnet_b0' provided by rwightman/pytorch-image-models (https://github.com/rwightman/pytorch-image-models).\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "model = ImageClassifier(backbone='efficientnet_b0',\n",
    "                        labels=train.classes,\n",
    "                        metrics=performance_metrics,\n",
    "                        loss_fn=LabelSmoothingCrossEntropy(0.02),\n",
    "                        optimizer=\"AdamW\",\n",
    "                        learning_rate=INIT_LR, )\n",
    "\n",
    "logger = CSVLogger(save_dir='logs/', version='30Epoch-NoFreeze')\n",
    "\n",
    "trainer = flash.Trainer(max_epochs=EPOCHS,\n",
    "                        gpus=torch.cuda.device_count(),\n",
    "                        logger=logger)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CYBORGX\\anaconda3\\envs\\birdclef\\lib\\site-packages\\flash\\core\\trainer.py:213: UserWarning: The model contains a default finetune callback.\n",
      "  warnings.warn(\"The model contains a default finetune callback.\", UserWarning)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type           | Params\n",
      "-------------------------------------------------\n",
      "0 | loss_fn       | ModuleDict     | 0     \n",
      "1 | train_metrics | ModuleDict     | 0     \n",
      "2 | val_metrics   | ModuleDict     | 0     \n",
      "3 | test_metrics  | ModuleDict     | 0     \n",
      "4 | adapter       | DefaultAdapter | 4.0 M \n",
      "-------------------------------------------------\n",
      "4.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 M     Total params\n",
      "16.122    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "66970fd1b1b047f38b310c0afd4f00e5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CYBORGX\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\CYBORGX\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41b153318571495ea05014806aba51d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59f678f02bf04fc4a36538398a28b357"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] total time taken to train the model: 2.59min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CYBORGX\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "trainer.finetune(model,\n",
    "                 datamodule=datamodule,\n",
    "                 strategy='no_freeze')\n",
    "\n",
    "endTime = time.time()\n",
    "print(f\"[INFO] total time taken to train the model: {(endTime - startTime) / 60 :.2f}min\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"saved-models/B0-Un.pt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "   train_accuracy_step  train_f1score_step  \\\n0             0.265625            0.133850   \n1             0.343750            0.243730   \n2                  NaN                 NaN   \n3                  NaN                 NaN   \n4             0.484375            0.380005   \n5             0.453125            0.387222   \n\n   train_labelsmoothingcrossentropy_step  epoch  step  val_accuracy  \\\n0                               2.457307      0    49           NaN   \n1                               2.180583      0    99           NaN   \n2                                    NaN      0   140      0.102513   \n3                                    NaN      0   140           NaN   \n4                               1.696713      1   149           NaN   \n5                               1.924132      1   199           NaN   \n\n   val_f1score  val_labelsmoothingcrossentropy  train_accuracy_epoch  \\\n0          NaN                             NaN                   NaN   \n1          NaN                             NaN                   NaN   \n2     0.036456                        2.768052                   NaN   \n3          NaN                             NaN              0.298205   \n4          NaN                             NaN                   NaN   \n5          NaN                             NaN                   NaN   \n\n   train_f1score_epoch  train_labelsmoothingcrossentropy_epoch  \n0                  NaN                                     NaN  \n1                  NaN                                     NaN  \n2                  NaN                                     NaN  \n3              0.21718                                 2.29969  \n4                  NaN                                     NaN  \n5                  NaN                                     NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train_accuracy_step</th>\n      <th>train_f1score_step</th>\n      <th>train_labelsmoothingcrossentropy_step</th>\n      <th>epoch</th>\n      <th>step</th>\n      <th>val_accuracy</th>\n      <th>val_f1score</th>\n      <th>val_labelsmoothingcrossentropy</th>\n      <th>train_accuracy_epoch</th>\n      <th>train_f1score_epoch</th>\n      <th>train_labelsmoothingcrossentropy_epoch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.265625</td>\n      <td>0.133850</td>\n      <td>2.457307</td>\n      <td>0</td>\n      <td>49</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.343750</td>\n      <td>0.243730</td>\n      <td>2.180583</td>\n      <td>0</td>\n      <td>99</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>140</td>\n      <td>0.102513</td>\n      <td>0.036456</td>\n      <td>2.768052</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>140</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.298205</td>\n      <td>0.21718</td>\n      <td>2.29969</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.484375</td>\n      <td>0.380005</td>\n      <td>1.696713</td>\n      <td>1</td>\n      <td>149</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.453125</td>\n      <td>0.387222</td>\n      <td>1.924132</td>\n      <td>1</td>\n      <td>199</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = pd.read_csv(f'{trainer.logger.log_dir}/metrics.csv')\n",
    "display(metrics)\n",
    "del metrics[\"epoch\"]\n",
    "metrics.set_index(\"step\", inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of            name   type1  encoded_label\n",
      "0     Bulbasaur   grass              9\n",
      "1       Ivysaur   grass              9\n",
      "2      Venusaur   grass              9\n",
      "3    Charmander    fire              6\n",
      "4    Charmeleon    fire              6\n",
      "..          ...     ...            ...\n",
      "714     Noivern  flying              7\n",
      "715     Xerneas   fairy              4\n",
      "716     Yveltal    dark              1\n",
      "718     Diancie    rock             15\n",
      "720   Volcanion    fire              6\n",
      "\n",
      "[703 rows x 3 columns]>\n",
      "   Type_name  encoded_type\n",
      "0      grass             9\n",
      "1       fire             6\n",
      "2      water            17\n",
      "3        bug             0\n",
      "4     normal            12\n",
      "5     poison            13\n",
      "6   electric             3\n",
      "7     ground            10\n",
      "8      fairy             4\n",
      "9   fighting             5\n",
      "10   psychic            14\n",
      "11      rock            15\n",
      "12     ghost             8\n",
      "13       ice            11\n",
      "14    dragon             2\n",
      "15      dark             1\n",
      "16     steel            16\n",
      "17    flying             7\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(filtered_metadata['type1'])\n",
    "filtered_metadata['encoded_label'] = labels\n",
    "\n",
    "type_list = filtered_metadata['type1'].unique()\n",
    "enc_type_list = filtered_metadata['encoded_label'].unique()\n",
    "\n",
    "type_lookup = pd.DataFrame(list(zip(type_list, enc_type_list)), columns=['Type_name', 'encoded_type'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\CYBORGX\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Predicting: 96it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d17c0102ba74c7c8aa3d9312b353784"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Pokemon had the predicted type:\n",
      "  Type_name  encoded_type\n",
      "4    normal            12\n",
      "---------------------------------------------------------------------\n",
      "- The Pokemon in Question actually has the type:\n",
      "       name   type1  encoded_label\n",
      "492  Arceus  normal             12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_data = ImageClassificationData.from_files(\n",
    "    predict_files=[\n",
    "        '../../Pokemon-data/Arceus/efplhfkrupqxdmke.png',\n",
    "    ],\n",
    "    batch_size = 1\n",
    ")\n",
    "\n",
    "predictions = trainer.predict(model, datamodule=pred_data, output=\"labels\")\n",
    "\n",
    "print(f\"\"\"\n",
    "- Pokemon had the predicted type:\n",
    "{type_lookup.loc[type_lookup['encoded_type'] == predictions[0][0]]}\n",
    "---------------------------------------------------------------------\n",
    "- The Pokemon in Question actually has the type:\n",
    "{filtered_metadata[filtered_metadata['name'] == 'Arceus']}\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
