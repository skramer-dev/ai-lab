{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchmetrics\n",
    "\n",
    "import time\n",
    "import torch.cuda\n",
    "from flash.image import ImageClassificationData, ImageClassifier\n",
    "import flash\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from timm.loss import LabelSmoothingCrossEntropy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio as iio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "DATA_PATH = '../../Pokemon-data/'\n",
    "NORMALIZED_DATA = '../../Training-baseline/'\n",
    "SEED = 42\n",
    "\n",
    "# define training hyperparameters\n",
    "INIT_LR = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "# define the train and val splits\n",
    "TRAIN_SPLIT = 0.75\n",
    "VAL_SPLIT = 1 - TRAIN_SPLIT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('metadata/pokemon.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['abilities', 'against_bug', 'against_dark', 'against_dragon',\n",
      "       'against_electric', 'against_fairy', 'against_fight', 'against_fire',\n",
      "       'against_flying', 'against_ghost', 'against_grass', 'against_ground',\n",
      "       'against_ice', 'against_normal', 'against_poison', 'against_psychic',\n",
      "       'against_rock', 'against_steel', 'against_water', 'attack',\n",
      "       'base_egg_steps', 'base_happiness', 'base_total', 'capture_rate',\n",
      "       'classfication', 'defense', 'experience_growth', 'height_m', 'hp',\n",
      "       'japanese_name', 'name', 'percentage_male', 'pokedex_number',\n",
      "       'sp_attack', 'sp_defense', 'speed', 'type1', 'type2', 'weight_kg',\n",
      "       'generation', 'is_legendary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(metadata.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "pokemon_names = [x for x in os.listdir(NORMALIZED_DATA)]\n",
    "\n",
    "# remove the IDE metafile that was included in the os.listdir\n",
    "#pokemon_names = pokemon_names[1:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# get slice from metadata file based on the pokemon used in training\n",
    "filtered_metadata = metadata[metadata.name.isin(pokemon_names)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# convert dataframe to list for easier comparison\n",
    "filtered_list = filtered_metadata.loc[:,'name'].tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# check for differences in training data and the metadata file\n",
    "print([x for x in pokemon_names if x not in filtered_list])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "filtered_metadata = filtered_metadata.loc[:,['name', 'type1']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of            name   type1\n",
      "0     Bulbasaur   grass\n",
      "1       Ivysaur   grass\n",
      "2      Venusaur   grass\n",
      "3    Charmander    fire\n",
      "4    Charmeleon    fire\n",
      "..          ...     ...\n",
      "714     Noivern  flying\n",
      "715     Xerneas   fairy\n",
      "716     Yveltal    dark\n",
      "718     Diancie    rock\n",
      "720   Volcanion    fire\n",
      "\n",
      "[703 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(filtered_metadata.head)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def compile_training_data_to_list():\n",
    "    all_data = []\n",
    "    for pokemon in os.listdir(NORMALIZED_DATA):\n",
    "        all_data += [pokemon + '/' + x for x in os.listdir(NORMALIZED_DATA + pokemon)]\n",
    "\n",
    "    results = create_annotated_dataframe(all_data)\n",
    "    return results\n",
    "\n",
    "def create_annotated_dataframe(all_data):\n",
    "    base_data = {'file_name': [], 'name': [], 'label': []}\n",
    "    for item in all_data:\n",
    "        base_data['file_name'].append(item)\n",
    "        base_data['name'].append(item.split('/')[0])\n",
    "        # yes, this is a bit ugly, but we have to match with the metadata\n",
    "        base_data['label'].append(\n",
    "            filtered_metadata[\n",
    "                filtered_metadata['name']==(item.split('/')[0])\n",
    "            ].loc[:,'type1'].tolist()[0])\n",
    "\n",
    "    results = create_encoded_dataframe(base_data)\n",
    "    return results\n",
    "\n",
    "def create_encoded_dataframe(base_data):\n",
    "    results = pd.DataFrame(base_data, columns = ['file_name', 'name', 'label'])\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(results['label'])\n",
    "    results['label'] = np.int64(labels)\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "encoded_data = compile_training_data_to_list()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            file_name       name  label\n",
      "0      Abomasnow/dcedzyqfojskcahp.jpg  Abomasnow      9\n",
      "1      Abomasnow/gqfpsmqasdqiknur.png  Abomasnow      9\n",
      "2      Abomasnow/imzcvkkckbdchpro.png  Abomasnow      9\n",
      "3      Abomasnow/kzibfmivzksykiwy.png  Abomasnow      9\n",
      "4      Abomasnow/mjtasvyoonxyilqt.png  Abomasnow      9\n",
      "...                               ...        ...    ...\n",
      "12091   Zweilous/nrpzbrzmxehydoqj.png   Zweilous      1\n",
      "12092   Zweilous/qjoppeepmpyujyao.png   Zweilous      1\n",
      "12093   Zweilous/sihxufnlbmephyeq.png   Zweilous      1\n",
      "12094   Zweilous/vshewhewmkutsdlp.png   Zweilous      1\n",
      "12095   Zweilous/ytpdigaymlnyrpbd.png   Zweilous      1\n",
      "\n",
      "[12096 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\tdef __init__(self, x, y, img_dir):\n",
    "\t\tself.x = x\n",
    "\t\tself.y = y\n",
    "\t\tself.img_dir = img_dir\n",
    "\t\tself.classes = np.unique(self.y)\n",
    "\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.x)\n",
    "\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timg_path = os.path.join(self.img_dir, self.x[idx])\n",
    "        # use the slice to remove a possible 4th alpha channel\n",
    "\t\timage = iio.v2.imread(img_path)[:,:,:3]\n",
    "\t\tlabel = self.y[idx]\n",
    "\t\treturn image, label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "def stratified_split(dataset):\n",
    "    x_train, x_val, y_train, y_val = train_test_split(dataset['file_name'].to_numpy(),\n",
    "                                                  dataset['label'].to_numpy(),\n",
    "                                                  test_size=0.25,\n",
    "                                                  stratify=dataset['label'],\n",
    "                                                  random_state=SEED)\n",
    "\n",
    "    train = CustomDataset(x_train, y_train, NORMALIZED_DATA)\n",
    "    val = CustomDataset(x_val, y_val, NORMALIZED_DATA)\n",
    "    return train, val"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "dataset = compile_training_data_to_list()\n",
    "train, val = stratified_split(dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "datamodule = ImageClassificationData.from_datasets(train_dataset=train,\n",
    "                                                   val_dataset=val,\n",
    "                                                   batch_size=BATCH_SIZE,\n",
    "                                                   )\n",
    "performance_metrics = [torchmetrics.Accuracy(),\n",
    "                      torchmetrics.F1Score(num_classes=len(train.classes), average='macro')]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 'efficientnet_b0' provided by rwightman/pytorch-image-models (https://github.com/rwightman/pytorch-image-models).\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "model = ImageClassifier(backbone='efficientnet_b0',\n",
    "                        labels=train.classes,\n",
    "                        metrics=performance_metrics,\n",
    "                        loss_fn=LabelSmoothingCrossEntropy(0.02),\n",
    "                        optimizer=\"AdamW\",\n",
    "                        learning_rate=INIT_LR, )\n",
    "\n",
    "logger = CSVLogger(save_dir='logs/', version=1)\n",
    "\n",
    "trainer = flash.Trainer(max_epochs=EPOCHS,\n",
    "                        gpus=torch.cuda.device_count(),\n",
    "                        logger=logger)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CYBORGX\\anaconda3\\envs\\birdclef\\lib\\site-packages\\flash\\core\\trainer.py:213: UserWarning: The model contains a default finetune callback.\n",
      "  warnings.warn(\"The model contains a default finetune callback.\", UserWarning)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type           | Params\n",
      "-------------------------------------------------\n",
      "0 | loss_fn       | ModuleDict     | 0     \n",
      "1 | train_metrics | ModuleDict     | 0     \n",
      "2 | val_metrics   | ModuleDict     | 0     \n",
      "3 | test_metrics  | ModuleDict     | 0     \n",
      "4 | adapter       | DefaultAdapter | 4.0 M \n",
      "-------------------------------------------------\n",
      "4.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 M     Total params\n",
      "16.122    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "badadeb9a6b84e42b0495c6a7b83d6aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CYBORGX\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\CYBORGX\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a3e1d9f7b6947d8a5aa54930417fcee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2e051ba2b2c456bb8c2bdc0fd1ce772"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "76707f850c4c4e0482c2f2c5e3dcd31f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b5000dce83a47e8b27eb13b9e4bacca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f2faacb874043c283b2ed277d8f2605"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69a268d4e44b47f3a3bbe1fd54c73b21"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1836ace965d248589846a6fea3dc0ceb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "acf85545ebbe4d67a8a9fb5d4a9ec4e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ad7b16717cd48e58fda936cb84c79f3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04a2f6924c7b4c42839bcf8f0b691dbb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validating: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d58884a5304444a0bcd2b462e2e690f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] total time taken to train the model: 16.03min\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "trainer.finetune(model,\n",
    "                 datamodule=datamodule,\n",
    "                 strategy='no_freeze')\n",
    "\n",
    "endTime = time.time()\n",
    "print(f\"[INFO] total time taken to train the model: {(endTime - startTime) / 60 :.2f}min\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"saved-models/B0-Un.pt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "    train_accuracy_step  train_f1score_step  \\\n0              0.265625            0.219432   \n1              0.312500            0.182998   \n2                   NaN                 NaN   \n3                   NaN                 NaN   \n4              0.406250            0.233752   \n5              0.437500            0.352732   \n6              0.593750            0.476157   \n7                   NaN                 NaN   \n8                   NaN                 NaN   \n9              0.656250            0.690476   \n10             0.687500            0.585493   \n11             0.656250            0.536994   \n12                  NaN                 NaN   \n13                  NaN                 NaN   \n14             0.875000            0.826413   \n15             0.750000            0.689651   \n16             0.671875            0.543903   \n17                  NaN                 NaN   \n18                  NaN                 NaN   \n19             0.906250            0.869111   \n20             0.796875            0.759103   \n21             0.859375            0.843995   \n22                  NaN                 NaN   \n23                  NaN                 NaN   \n24             0.812500            0.600997   \n25             0.890625            0.877715   \n26                  NaN                 NaN   \n27                  NaN                 NaN   \n28             0.890625            0.864425   \n29             0.937500            0.901774   \n30             0.906250            0.887653   \n31                  NaN                 NaN   \n32                  NaN                 NaN   \n33             0.937500            0.843050   \n34             0.953125            0.974754   \n35             0.921875            0.946332   \n36                  NaN                 NaN   \n37                  NaN                 NaN   \n38             0.906250            0.881105   \n39             0.953125            0.950267   \n40             0.921875            0.831486   \n41                  NaN                 NaN   \n42                  NaN                 NaN   \n43             0.968750            0.905133   \n44             0.953125            0.903764   \n45             0.906250            0.908730   \n46                  NaN                 NaN   \n47                  NaN                 NaN   \n\n    train_labelsmoothingcrossentropy_step  epoch  step  val_accuracy  \\\n0                                2.407875      0    49           NaN   \n1                                2.133457      0    99           NaN   \n2                                     NaN      0   140      0.250661   \n3                                     NaN      0   140           NaN   \n4                                2.028200      1   149           NaN   \n5                                1.761731      1   199           NaN   \n6                                1.417017      1   249           NaN   \n7                                     NaN      1   281      0.207341   \n8                                     NaN      1   281           NaN   \n9                                1.153270      2   299           NaN   \n10                               1.083587      2   349           NaN   \n11                               1.135579      2   399           NaN   \n12                                    NaN      2   422      0.113426   \n13                                    NaN      2   422           NaN   \n14                               0.637418      3   449           NaN   \n15                               0.869341      3   499           NaN   \n16                               1.089309      3   549           NaN   \n17                                    NaN      3   563      0.296296   \n18                                    NaN      3   563           NaN   \n19                               0.461090      4   599           NaN   \n20                               0.695016      4   649           NaN   \n21                               0.681571      4   699           NaN   \n22                                    NaN      4   704      0.226190   \n23                                    NaN      4   704           NaN   \n24                               0.682944      5   749           NaN   \n25                               0.511513      5   799           NaN   \n26                                    NaN      5   845      0.238426   \n27                                    NaN      5   845           NaN   \n28                               0.459108      6   849           NaN   \n29                               0.480027      6   899           NaN   \n30                               0.469590      6   949           NaN   \n31                                    NaN      6   986      0.507606   \n32                                    NaN      6   986           NaN   \n33                               0.389797      7   999           NaN   \n34                               0.367859      7  1049           NaN   \n35                               0.376245      7  1099           NaN   \n36                                    NaN      7  1127      0.305225   \n37                                    NaN      7  1127           NaN   \n38                               0.450314      8  1149           NaN   \n39                               0.361188      8  1199           NaN   \n40                               0.439237      8  1249           NaN   \n41                                    NaN      8  1268      0.318122   \n42                                    NaN      8  1268           NaN   \n43                               0.340580      9  1299           NaN   \n44                               0.358521      9  1349           NaN   \n45                               0.463317      9  1399           NaN   \n46                                    NaN      9  1409      0.484788   \n47                                    NaN      9  1409           NaN   \n\n    val_f1score  val_labelsmoothingcrossentropy  train_accuracy_epoch  \\\n0           NaN                             NaN                   NaN   \n1           NaN                             NaN                   NaN   \n2      0.206287                        2.422107                   NaN   \n3           NaN                             NaN              0.274712   \n4           NaN                             NaN                   NaN   \n5           NaN                             NaN                   NaN   \n6           NaN                             NaN                   NaN   \n7      0.190536                        2.500473                   NaN   \n8           NaN                             NaN              0.481937   \n9           NaN                             NaN                   NaN   \n10          NaN                             NaN                   NaN   \n11          NaN                             NaN                   NaN   \n12     0.077681                        2.794824                   NaN   \n13          NaN                             NaN              0.637079   \n14          NaN                             NaN                   NaN   \n15          NaN                             NaN                   NaN   \n16          NaN                             NaN                   NaN   \n17     0.256525                        2.426930                   NaN   \n18          NaN                             NaN              0.747340   \n19          NaN                             NaN                   NaN   \n20          NaN                             NaN                   NaN   \n21          NaN                             NaN                   NaN   \n22     0.140042                        2.507103                   NaN   \n23          NaN                             NaN              0.832225   \n24          NaN                             NaN                   NaN   \n25          NaN                             NaN                   NaN   \n26     0.187378                        2.585999                   NaN   \n27          NaN                             NaN              0.875886   \n28          NaN                             NaN                   NaN   \n29          NaN                             NaN                   NaN   \n30          NaN                             NaN                   NaN   \n31     0.451630                        1.892786                   NaN   \n32          NaN                             NaN              0.909353   \n33          NaN                             NaN                   NaN   \n34          NaN                             NaN                   NaN   \n35          NaN                             NaN                   NaN   \n36     0.253100                        2.407785                   NaN   \n37          NaN                             NaN              0.922097   \n38          NaN                             NaN                   NaN   \n39          NaN                             NaN                   NaN   \n40          NaN                             NaN                   NaN   \n41     0.252758                        2.593154                   NaN   \n42          NaN                             NaN              0.936835   \n43          NaN                             NaN                   NaN   \n44          NaN                             NaN                   NaN   \n45          NaN                             NaN                   NaN   \n46     0.429332                        2.069952                   NaN   \n47          NaN                             NaN              0.943706   \n\n    train_f1score_epoch  train_labelsmoothingcrossentropy_epoch  \n0                   NaN                                     NaN  \n1                   NaN                                     NaN  \n2                   NaN                                     NaN  \n3              0.193758                                2.345324  \n4                   NaN                                     NaN  \n5                   NaN                                     NaN  \n6                   NaN                                     NaN  \n7                   NaN                                     NaN  \n8              0.425023                                1.723214  \n9                   NaN                                     NaN  \n10                  NaN                                     NaN  \n11                  NaN                                     NaN  \n12                  NaN                                     NaN  \n13             0.578770                                1.260979  \n14                  NaN                                     NaN  \n15                  NaN                                     NaN  \n16                  NaN                                     NaN  \n17                  NaN                                     NaN  \n18             0.702168                                0.924967  \n19                  NaN                                     NaN  \n20                  NaN                                     NaN  \n21                  NaN                                     NaN  \n22                  NaN                                     NaN  \n23             0.794711                                0.678331  \n24                  NaN                                     NaN  \n25                  NaN                                     NaN  \n26                  NaN                                     NaN  \n27             0.870951                                0.548608  \n28                  NaN                                     NaN  \n29                  NaN                                     NaN  \n30                  NaN                                     NaN  \n31                  NaN                                     NaN  \n32             0.909919                                0.455123  \n33                  NaN                                     NaN  \n34                  NaN                                     NaN  \n35                  NaN                                     NaN  \n36                  NaN                                     NaN  \n37             0.923960                                0.410780  \n38                  NaN                                     NaN  \n39                  NaN                                     NaN  \n40                  NaN                                     NaN  \n41                  NaN                                     NaN  \n42             0.942560                                0.380618  \n43                  NaN                                     NaN  \n44                  NaN                                     NaN  \n45                  NaN                                     NaN  \n46                  NaN                                     NaN  \n47             0.950996                                0.357974  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train_accuracy_step</th>\n      <th>train_f1score_step</th>\n      <th>train_labelsmoothingcrossentropy_step</th>\n      <th>epoch</th>\n      <th>step</th>\n      <th>val_accuracy</th>\n      <th>val_f1score</th>\n      <th>val_labelsmoothingcrossentropy</th>\n      <th>train_accuracy_epoch</th>\n      <th>train_f1score_epoch</th>\n      <th>train_labelsmoothingcrossentropy_epoch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.265625</td>\n      <td>0.219432</td>\n      <td>2.407875</td>\n      <td>0</td>\n      <td>49</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.312500</td>\n      <td>0.182998</td>\n      <td>2.133457</td>\n      <td>0</td>\n      <td>99</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>140</td>\n      <td>0.250661</td>\n      <td>0.206287</td>\n      <td>2.422107</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>140</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.274712</td>\n      <td>0.193758</td>\n      <td>2.345324</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.406250</td>\n      <td>0.233752</td>\n      <td>2.028200</td>\n      <td>1</td>\n      <td>149</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.437500</td>\n      <td>0.352732</td>\n      <td>1.761731</td>\n      <td>1</td>\n      <td>199</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.593750</td>\n      <td>0.476157</td>\n      <td>1.417017</td>\n      <td>1</td>\n      <td>249</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>281</td>\n      <td>0.207341</td>\n      <td>0.190536</td>\n      <td>2.500473</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>281</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.481937</td>\n      <td>0.425023</td>\n      <td>1.723214</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.656250</td>\n      <td>0.690476</td>\n      <td>1.153270</td>\n      <td>2</td>\n      <td>299</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.687500</td>\n      <td>0.585493</td>\n      <td>1.083587</td>\n      <td>2</td>\n      <td>349</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.656250</td>\n      <td>0.536994</td>\n      <td>1.135579</td>\n      <td>2</td>\n      <td>399</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>422</td>\n      <td>0.113426</td>\n      <td>0.077681</td>\n      <td>2.794824</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>422</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.637079</td>\n      <td>0.578770</td>\n      <td>1.260979</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.875000</td>\n      <td>0.826413</td>\n      <td>0.637418</td>\n      <td>3</td>\n      <td>449</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.750000</td>\n      <td>0.689651</td>\n      <td>0.869341</td>\n      <td>3</td>\n      <td>499</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.671875</td>\n      <td>0.543903</td>\n      <td>1.089309</td>\n      <td>3</td>\n      <td>549</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>563</td>\n      <td>0.296296</td>\n      <td>0.256525</td>\n      <td>2.426930</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>563</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.747340</td>\n      <td>0.702168</td>\n      <td>0.924967</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.906250</td>\n      <td>0.869111</td>\n      <td>0.461090</td>\n      <td>4</td>\n      <td>599</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.796875</td>\n      <td>0.759103</td>\n      <td>0.695016</td>\n      <td>4</td>\n      <td>649</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.859375</td>\n      <td>0.843995</td>\n      <td>0.681571</td>\n      <td>4</td>\n      <td>699</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>704</td>\n      <td>0.226190</td>\n      <td>0.140042</td>\n      <td>2.507103</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>704</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.832225</td>\n      <td>0.794711</td>\n      <td>0.678331</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.812500</td>\n      <td>0.600997</td>\n      <td>0.682944</td>\n      <td>5</td>\n      <td>749</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.890625</td>\n      <td>0.877715</td>\n      <td>0.511513</td>\n      <td>5</td>\n      <td>799</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>845</td>\n      <td>0.238426</td>\n      <td>0.187378</td>\n      <td>2.585999</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>845</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.875886</td>\n      <td>0.870951</td>\n      <td>0.548608</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.890625</td>\n      <td>0.864425</td>\n      <td>0.459108</td>\n      <td>6</td>\n      <td>849</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.937500</td>\n      <td>0.901774</td>\n      <td>0.480027</td>\n      <td>6</td>\n      <td>899</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0.906250</td>\n      <td>0.887653</td>\n      <td>0.469590</td>\n      <td>6</td>\n      <td>949</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6</td>\n      <td>986</td>\n      <td>0.507606</td>\n      <td>0.451630</td>\n      <td>1.892786</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6</td>\n      <td>986</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.909353</td>\n      <td>0.909919</td>\n      <td>0.455123</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>0.937500</td>\n      <td>0.843050</td>\n      <td>0.389797</td>\n      <td>7</td>\n      <td>999</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>0.953125</td>\n      <td>0.974754</td>\n      <td>0.367859</td>\n      <td>7</td>\n      <td>1049</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>0.921875</td>\n      <td>0.946332</td>\n      <td>0.376245</td>\n      <td>7</td>\n      <td>1099</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>1127</td>\n      <td>0.305225</td>\n      <td>0.253100</td>\n      <td>2.407785</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>1127</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.922097</td>\n      <td>0.923960</td>\n      <td>0.410780</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>0.906250</td>\n      <td>0.881105</td>\n      <td>0.450314</td>\n      <td>8</td>\n      <td>1149</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>0.953125</td>\n      <td>0.950267</td>\n      <td>0.361188</td>\n      <td>8</td>\n      <td>1199</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>0.921875</td>\n      <td>0.831486</td>\n      <td>0.439237</td>\n      <td>8</td>\n      <td>1249</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>1268</td>\n      <td>0.318122</td>\n      <td>0.252758</td>\n      <td>2.593154</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>1268</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.936835</td>\n      <td>0.942560</td>\n      <td>0.380618</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>0.968750</td>\n      <td>0.905133</td>\n      <td>0.340580</td>\n      <td>9</td>\n      <td>1299</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>0.953125</td>\n      <td>0.903764</td>\n      <td>0.358521</td>\n      <td>9</td>\n      <td>1349</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>0.906250</td>\n      <td>0.908730</td>\n      <td>0.463317</td>\n      <td>9</td>\n      <td>1399</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9</td>\n      <td>1409</td>\n      <td>0.484788</td>\n      <td>0.429332</td>\n      <td>2.069952</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9</td>\n      <td>1409</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.943706</td>\n      <td>0.950996</td>\n      <td>0.357974</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = pd.read_csv(f'{trainer.logger.log_dir}/metrics.csv')\n",
    "display(metrics)\n",
    "del metrics[\"epoch\"]\n",
    "metrics.set_index(\"step\", inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
