{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../../Pokemon-data/'\n",
    "NORMALIZED_DATA = '../../Training-baseline/'\n",
    "AUGMENTATION_PATH = '../../pipe_one_aug/'\n",
    "CSV_NAME = \"training-list.csv\"\n",
    "SEED = 42\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "MODEL_NAME = \"aug-freeze-customLR\"\n",
    "checkpoint_path = '../saved-models/'\n",
    "TRAINING_METRICS = '../training-metrics/'\n",
    "n_epochs_stop = 3\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y, img_dir):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.img_dir = img_dir\n",
    "        self.classes = np.unique(self.y)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.x[idx])\n",
    "        # use the slice to remove a possible 4th alpha channel\n",
    "        image = np.load(img_path)[:,:,:3]\n",
    "        image = image.astype(np.float32)\n",
    "        label = self.y[idx]\n",
    "        return image, label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "def stratified_split(dataset, labels):\n",
    "    x_train, x_val, y_train, y_val = train_test_split(dataset['file_name'].to_numpy(),\n",
    "                                                      labels,\n",
    "                                                      test_size=0.25,\n",
    "                                                      stratify=dataset['label'],\n",
    "                                                      random_state=SEED)\n",
    "\n",
    "    trainSet = CustomDataset(x_train, y_train, AUGMENTATION_PATH)\n",
    "    valSet = CustomDataset(x_val, y_val, AUGMENTATION_PATH)\n",
    "    return trainSet, valSet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "# read data\n",
    "csv_data = pd.read_csv(f\"../metadata/{CSV_NAME}\", index_col=0)\n",
    "\n",
    "y_train = np.zeros((len(csv_data[\"y_train_columns\"]),csv_data[\"y_train_columns\"][0]))\n",
    "for i in range(csv_data[\"y_train_columns\"][0]):\n",
    "    y_train[:,i] = csv_data[\"y_train\"+str(i)]\n",
    "\n",
    "encoded_data = csv_data.drop(csv_data.columns[(csv_data.shape[1]-csv_data[\"y_train_columns\"][0]-1):csv_data.shape[1]], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9059\n",
      "3020\n",
      "['Girafarig/azvrgkiycubwviye.npy'\n",
      " 'Arbok/3e4fd8cdf8c740548826b6de29f18258.npy'\n",
      " 'Poliwhirl/d843aea788dd48f586ffdf8736dd3c4c.npy' ...\n",
      " 'Drowzee/f3019e459027400182e15bf74e571c92.npy'\n",
      " 'Haxorus/ifhrniyifefkmknn.npy'\n",
      " 'Lickitung/52c26d87db7847789148ea4e3c64819c.npy']\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "train, val = stratified_split(encoded_data, y_train)\n",
    "print(len(train.x))\n",
    "print(len(val.x))\n",
    "print(val.x)\n",
    "print(type(val.x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25073\n",
      "<bound method NDFrame.head of                               file_name       name  label  y_train0  y_train1  \\\n",
      "0      Abomasnow/dcedzyqfojskcahp_0.npy  Abomasnow      9       0.0       0.0   \n",
      "1      Abomasnow/gqfpsmqasdqiknur_0.npy  Abomasnow      9       0.0       0.0   \n",
      "2      Abomasnow/imzcvkkckbdchpro_0.npy  Abomasnow      9       0.0       0.0   \n",
      "3      Abomasnow/kzibfmivzksykiwy_0.npy  Abomasnow      9       0.0       0.0   \n",
      "4      Abomasnow/mjtasvyoonxyilqt_0.npy  Abomasnow      9       0.0       0.0   \n",
      "...                                 ...        ...    ...       ...       ...   \n",
      "25068   Zweilous/nrpzbrzmxehydoqj_0.npy   Zweilous      1       0.0       1.0   \n",
      "25069   Zweilous/qjoppeepmpyujyao_0.npy   Zweilous      1       0.0       1.0   \n",
      "25070   Zweilous/sihxufnlbmephyeq_0.npy   Zweilous      1       0.0       1.0   \n",
      "25071   Zweilous/vshewhewmkutsdlp_0.npy   Zweilous      1       0.0       1.0   \n",
      "25072   Zweilous/ytpdigaymlnyrpbd_0.npy   Zweilous      1       0.0       1.0   \n",
      "\n",
      "       y_train2  y_train3  y_train4  y_train5  y_train6  ...  y_train9  \\\n",
      "0           0.0       0.0       0.0       0.0       0.0  ...       1.0   \n",
      "1           0.0       0.0       0.0       0.0       0.0  ...       1.0   \n",
      "2           0.0       0.0       0.0       0.0       0.0  ...       1.0   \n",
      "3           0.0       0.0       0.0       0.0       0.0  ...       1.0   \n",
      "4           0.0       0.0       0.0       0.0       0.0  ...       1.0   \n",
      "...         ...       ...       ...       ...       ...  ...       ...   \n",
      "25068       0.0       0.0       0.0       0.0       0.0  ...       0.0   \n",
      "25069       0.0       0.0       0.0       0.0       0.0  ...       0.0   \n",
      "25070       0.0       0.0       0.0       0.0       0.0  ...       0.0   \n",
      "25071       0.0       0.0       0.0       0.0       0.0  ...       0.0   \n",
      "25072       0.0       0.0       0.0       0.0       0.0  ...       0.0   \n",
      "\n",
      "       y_train10  y_train11  y_train12  y_train13  y_train14  y_train15  \\\n",
      "0            0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "1            0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "2            0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "3            0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "4            0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "...          ...        ...        ...        ...        ...        ...   \n",
      "25068        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "25069        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "25070        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "25071        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "25072        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "\n",
      "       y_train16  y_train17  y_train_columns  \n",
      "0            0.0        0.0               18  \n",
      "1            0.0        0.0               18  \n",
      "2            0.0        0.0               18  \n",
      "3            0.0        0.0               18  \n",
      "4            0.0        0.0               18  \n",
      "...          ...        ...              ...  \n",
      "25068        0.0        0.0               18  \n",
      "25069        0.0        0.0               18  \n",
      "25070        0.0        0.0               18  \n",
      "25071        0.0        0.0               18  \n",
      "25072        0.0        0.0               18  \n",
      "\n",
      "[25073 rows x 22 columns]>\n"
     ]
    }
   ],
   "source": [
    "extended_csv = pd.read_csv(f\"../metadata/aug-training-list.csv\", index_col=0)\n",
    "print(len(extended_csv))\n",
    "print(extended_csv.head)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "for idx, e in enumerate(val.x):\n",
    "    name = e.split('.')[0] + '_0.' + e.split('.')[1]\n",
    "    val.x[idx] = name"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        file_name   name  label  y_train0  \\\n",
      "419  Arbok/3e4fd8cdf8c740548826b6de29f18258_0.npy  Arbok     13       0.0   \n",
      "\n",
      "     y_train1  y_train2  y_train3  y_train4  y_train5  y_train6  ...  \\\n",
      "419       0.0       0.0       0.0       0.0       0.0       0.0  ...   \n",
      "\n",
      "     y_train9  y_train10  y_train11  y_train12  y_train13  y_train14  \\\n",
      "419       0.0        0.0        0.0        0.0        1.0        0.0   \n",
      "\n",
      "     y_train15  y_train16  y_train17  y_train_columns  \n",
      "419        0.0        0.0        0.0               18  \n",
      "\n",
      "[1 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(extended_csv[extended_csv.file_name == \"Arbok/3e4fd8cdf8c740548826b6de29f18258_0.npy\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22055\n",
      "22055\n"
     ]
    }
   ],
   "source": [
    "extended_csv = extended_csv[~extended_csv.file_name.isin(val.x.tolist())]\n",
    "\n",
    "y_train = np.zeros((len(extended_csv[\"y_train_columns\"]),extended_csv[\"y_train_columns\"][0]))\n",
    "for i in range(extended_csv[\"y_train_columns\"][0]):\n",
    "    y_train[:,i] = extended_csv[\"y_train\"+str(i)]\n",
    "\n",
    "encoded_data = extended_csv.drop(extended_csv.columns[(extended_csv.shape[1]-extended_csv[\"y_train_columns\"][0]-1):extended_csv.shape[1]], axis=1)\n",
    "\n",
    "print(len(encoded_data))\n",
    "print(len(y_train))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              file_name       name  label\n",
      "0      Abomasnow/dcedzyqfojskcahp_0.npy  Abomasnow      9\n",
      "1      Abomasnow/gqfpsmqasdqiknur_0.npy  Abomasnow      9\n",
      "2      Abomasnow/imzcvkkckbdchpro_0.npy  Abomasnow      9\n",
      "3      Abomasnow/kzibfmivzksykiwy_0.npy  Abomasnow      9\n",
      "4      Abomasnow/mjtasvyoonxyilqt_0.npy  Abomasnow      9\n",
      "...                                 ...        ...    ...\n",
      "25065   Zweilous/itjsfinjnbuxsymt_0.npy   Zweilous      1\n",
      "25066   Zweilous/izpqcbvdywrnuwwv_0.npy   Zweilous      1\n",
      "25067   Zweilous/lcsoqwhymtkbtnow_0.npy   Zweilous      1\n",
      "25069   Zweilous/qjoppeepmpyujyao_0.npy   Zweilous      1\n",
      "25070   Zweilous/sihxufnlbmephyeq_0.npy   Zweilous      1\n",
      "\n",
      "[22055 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
