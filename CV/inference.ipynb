{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from IPython.display import Image\n",
    "from scipy.special import softmax\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'Conv2dNormActivation' on <module 'torchvision.ops.misc' from 'C:\\\\Users\\\\CYBORGX\\\\anaconda3\\\\envs\\\\birdclef\\\\lib\\\\site-packages\\\\torchvision\\\\ops\\\\misc.py'>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [15]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m numpy_data_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../../Training-baseline/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      2\u001B[0m image_data_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../../Pokemon-data/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 4\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./saved-models/20Epochs-no-freeze-customLR.pt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mcpu()\n\u001B[0;32m      6\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\torch\\serialization.py:712\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[0;32m    710\u001B[0m             opened_file\u001B[38;5;241m.\u001B[39mseek(orig_position)\n\u001B[0;32m    711\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mload(opened_file)\n\u001B[1;32m--> 712\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _load(opened_zipfile, map_location, pickle_module, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[0;32m    713\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\torch\\serialization.py:1046\u001B[0m, in \u001B[0;36m_load\u001B[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1044\u001B[0m unpickler \u001B[38;5;241m=\u001B[39m UnpicklerWrapper(data_file, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[0;32m   1045\u001B[0m unpickler\u001B[38;5;241m.\u001B[39mpersistent_load \u001B[38;5;241m=\u001B[39m persistent_load\n\u001B[1;32m-> 1046\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43munpickler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1048\u001B[0m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_validate_loaded_sparse_tensors()\n\u001B[0;32m   1050\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\birdclef\\lib\\site-packages\\torch\\serialization.py:1039\u001B[0m, in \u001B[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001B[1;34m(self, mod_name, name)\u001B[0m\n\u001B[0;32m   1037\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m   1038\u001B[0m mod_name \u001B[38;5;241m=\u001B[39m load_module_mapping\u001B[38;5;241m.\u001B[39mget(mod_name, mod_name)\n\u001B[1;32m-> 1039\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind_class\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mAttributeError\u001B[0m: Can't get attribute 'Conv2dNormActivation' on <module 'torchvision.ops.misc' from 'C:\\\\Users\\\\CYBORGX\\\\anaconda3\\\\envs\\\\birdclef\\\\lib\\\\site-packages\\\\torchvision\\\\ops\\\\misc.py'>"
     ]
    }
   ],
   "source": [
    "numpy_data_path = \"../../Training-baseline/\"\n",
    "image_data_path = \"../../Pokemon-data/\"\n",
    "\n",
    "model = torch.load(\"./saved-models/20Epochs-no-freeze-customLR.pt\")\n",
    "model = model.cpu()\n",
    "model.eval()\n",
    "\n",
    "metadata = pd.read_csv('metadata/pokemon.csv')\n",
    "\n",
    "filtered_metadata = metadata.loc[:,['name', 'type1']]\n",
    "filtered_metadata.type1 = pd.Categorical(filtered_metadata.type1)\n",
    "filtered_metadata['code'] = filtered_metadata.type1.cat.codes\n",
    "filtered_metadata = filtered_metadata[[\"type1\", \"code\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_type(idx):\n",
    "    return filtered_metadata[filtered_metadata[\"code\"] == idx][\"type1\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(name):\n",
    "    numpy_files = os.listdir(numpy_data_path+name)\n",
    "    image_files = os.listdir(image_data_path+name)\n",
    "    file_idx = random.choice(list(enumerate(numpy_files)))[0]\n",
    "    display(Image(filename=image_data_path+name+\"/\"+image_files[file_idx], width = 500, height = 300))\n",
    "    image_array = np.load(numpy_data_path+name+\"/\"+numpy_files[file_idx])[:,:,:3]\n",
    "    data = image_array.astype(np.float32)\n",
    "    \n",
    "    data = data.transpose()\n",
    "    data = data[None,:,:,:]\n",
    "    data = torch.tensor(data, dtype=torch.float)\n",
    "    prediction = model(data).detach().numpy()[0]\n",
    "\n",
    "    confident_idx = np.argmax(prediction)\n",
    "    print(f\"Model predicted: {extract_type(confident_idx)}\")\n",
    "    prediction = [(extract_type(idx), single_prediction) for idx, single_prediction in enumerate((softmax(prediction)*100))]\n",
    "    prediction.sort(key=lambda x: x[1], reverse=True)\n",
    "    prediction = [f\"{single_prediction[0]}: {single_prediction[1]:.2f}%\" for single_prediction in prediction]\n",
    "    \n",
    "    for idx, single_prediction in enumerate(prediction):\n",
    "        print(single_prediction, end='\\t')\n",
    "        if (idx + 1) % 6 == 0:\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gewünschte Pokemon in der test_pokemon_list hinzufügen (in Englisch, mehrfach auflisten ist möglich)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pokemon_list = [\"Bulbasaur\", \"Charizard\", \"Golduck\", \"Groudon\", \"Kyogre\"]\n",
    "for pokemon in test_pokemon_list:\n",
    "    make_prediction(pokemon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ki-lab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8264f563574424d24d12a45a7d14379defa3be27ef947163ce9eeda193eace4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
