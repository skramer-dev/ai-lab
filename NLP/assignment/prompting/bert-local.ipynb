{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\python\\lib\\site-packages\\transformers\\generation_utils.py:27: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from openprompt import PromptDataLoader, PromptForClassification\n",
    "from openprompt.data_utils import InputExample, InputFeatures\n",
    "from openprompt.plms import load_plm\n",
    "from openprompt.prompts import ManualTemplate, ManualVerbalizer, ManualTemplate\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "plm, tokenizer, model_config, WrapperClass = load_plm(\"bert\", \"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration dataset-294e9b13f49dafc6\n",
      "Found cached dataset csv (C:/Users/fst/.cache/huggingface/datasets/csv/dataset-294e9b13f49dafc6/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4ea75cd6584c23821f8ca9d94ec919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "pokemon_descriptions = load_dataset('../data/dataset/', delimiter=';')\n",
    "NUM_CLASSES = np.unique(pokemon_descriptions['train']['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "split_pokemon_descriptions = pokemon_descriptions['train'].train_test_split(\n",
    "    test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate InputExamples from existing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "for split in ['train']:\n",
    "    dataset[split] = []\n",
    "    for sample in split_pokemon_descriptions[split]:\n",
    "        input_example = InputExample(text_a = sample['text'], label=int(sample['labels']))\n",
    "        dataset[split].append(input_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'text': 'There are several small, yellowish crystals scattered across its body and iron sand attracted by magnetism', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': ' the pokemon is', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}], {'label': 74}]\n"
     ]
    }
   ],
   "source": [
    "promptTemplate = ManualTemplate(\n",
    "    text = '{\"placeholder\":\"text_a\"} the pokemon is {\"mask\"}',\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "wrapped_example = promptTemplate.wrap_one_example(dataset['train'][0])\n",
    "print(wrapped_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create verbalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = pd.read_csv('../data/pokemon_mapping.csv')\n",
    "name_to_label_dict = mappings[[\"name\",\"index\"]].set_index('index').to_dict()[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptVerbalizer = ManualVerbalizer(\n",
    "    classes = NUM_CLASSES,\n",
    "    label_words = name_to_label_dict,\n",
    "    tokenizer = tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 8631it [00:07, 1191.73it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = PromptDataLoader(\n",
    "  dataset=dataset[\"train\"],\n",
    "  template=promptTemplate, \n",
    "  tokenizer=tokenizer,\n",
    "  tokenizer_wrapper_class=WrapperClass, \n",
    "  shuffle=True,\n",
    "  truncate_method=\"head\",\n",
    "  decoder_max_length=3,\n",
    "  batch_size=16,\n",
    "  teacher_forcing=False,\n",
    "  predict_eos_token=False,\n",
    "  max_seq_length=80,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptModel = PromptForClassification(\n",
    "    template = promptTemplate,\n",
    "    plm = plm,\n",
    "    verbalizer = promptVerbalizer,\n",
    "    freeze_plm= False\n",
    ")\n",
    "promptModel= promptModel.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "no_decay = ['bias', 'layer_norm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in promptModel.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in promptModel.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = torch.optim.AdamW(params=optimizer_grouped_parameters)\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, average loss: 7.08217716217041\n",
      "Epoch 0, average loss: 6.1215168509152855\n",
      "Epoch 0, average loss: 5.61420868403876\n",
      "Epoch 0, average loss: 5.438236718161954\n",
      "Epoch 0, average loss: 5.348947370438801\n",
      "Epoch 0, average loss: 5.293366494055042\n",
      "Epoch 1, average loss: 4.999392032623291\n",
      "Epoch 1, average loss: 5.071452324933345\n",
      "Epoch 1, average loss: 5.072045409264256\n",
      "Epoch 1, average loss: 5.07404838447951\n",
      "Epoch 1, average loss: 5.069258875383106\n",
      "Epoch 1, average loss: 5.069009586722551\n",
      "Epoch 2, average loss: 4.9311604499816895\n",
      "Epoch 2, average loss: 5.05151632516691\n",
      "Epoch 2, average loss: 5.057443704178084\n",
      "Epoch 2, average loss: 5.057116315214341\n",
      "Epoch 2, average loss: 5.059043224315691\n",
      "Epoch 2, average loss: 5.059736605889783\n",
      "Epoch 3, average loss: 5.115413665771484\n",
      "Epoch 3, average loss: 5.047688078172136\n",
      "Epoch 3, average loss: 5.048951258113728\n",
      "Epoch 3, average loss: 5.045740878463188\n",
      "Epoch 3, average loss: 5.046302028427695\n",
      "Epoch 3, average loss: 5.045262187302946\n",
      "Epoch 4, average loss: 4.870874404907227\n",
      "Epoch 4, average loss: 5.0318504418476975\n",
      "Epoch 4, average loss: 5.031021013781799\n",
      "Epoch 4, average loss: 5.032531217087147\n",
      "Epoch 4, average loss: 5.0323505984280175\n",
      "Epoch 4, average loss: 5.032259677460569\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    tot_loss = 0\n",
    "    for step, inputs in enumerate(train_dataloader):\n",
    "        inputs = inputs.cuda()\n",
    "        logits = promptModel(inputs)\n",
    "        labels = inputs['label']\n",
    "        loss = loss_func(logits, labels)\n",
    "        loss.backward()\n",
    "        tot_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if step %100 == 0:\n",
    "            print(\"Epoch {}, average loss: {}\".format(epoch, tot_loss/(step+1)), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(promptModel.state_dict(),\"checkp/bert_trained_model.cp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versuch 1\n",
    "\n",
    "- True = [133, 12, 46, 44, 70, 0, 101, 134, 113, 109, 136, 38, 91, 143, 59, 110, 127, 116, 98, 80, 149, 48, 46]\n",
    "- Predicted = [ 94,  78,  94,  94,  78, 105,  94,  94,  94,  94,  54,  94,  94,  78, 98,  94,  78,  94,  94, 105,  28,  78,  94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = {}\n",
    "for split in ['test']:\n",
    "    dataset_test[split] = []\n",
    "    for sample in split_pokemon_descriptions[split]:\n",
    "        input_example = InputExample(text_a = sample['text'], label=int(sample['labels']))\n",
    "        dataset_test[split].append(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 2158it [00:01, 1147.08it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = PromptDataLoader(dataset=dataset_test[\"test\"], template=promptTemplate, tokenizer=tokenizer,\n",
    "    tokenizer_wrapper_class=WrapperClass, max_seq_length=250, decoder_max_length=3,\n",
    "    batch_size=1,shuffle=False, teacher_forcing=False, predict_eos_token=False,\n",
    "    truncate_method=\"head\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007877664504170528\n"
     ]
    }
   ],
   "source": [
    "allpreds = []\n",
    "alllabels = []\n",
    "for step, inputs in enumerate(test_dataloader):\n",
    "    inputs = inputs.cuda()\n",
    "    logits = promptModel(inputs)\n",
    "    labels = inputs['label']\n",
    "    alllabels.extend(labels.cuda().tolist())\n",
    "    allpreds.extend(torch.argmax(logits, dim=-1).cuda().tolist())\n",
    "\n",
    "acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45037c9fa964e33746a67959e611b1255904e81b18931a74a47f598c93f55abd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
